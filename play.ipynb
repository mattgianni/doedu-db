{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook converts the schoolList.json file from the web scraping process into a prisma seed file. The prisma seed file is used to populate the database with the school data.\n",
    "\n",
    "This conversion is partial manual since the school from the SFUSD website are not a perfect match for the data submitted to the CA Department of Education. The workbook attempts to match the records on a combination of zipcode and school name, but the algorithm is not perfect. In cases of low quality matches, the casid (short for CA School ID) can be confirmed by looking at the SARC document for the school (located in Google Drive folders).\n",
    "\n",
    "This workbook also removes the schools that are not in the California Department of Education databases. These schools are typically preschools or non-degree granting institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function finds the best match for a school name in a given zipcode\n",
    "from difflib import SequenceMatcher as SM\n",
    "\n",
    "def best_match(qmap, school_name, zipcode):\n",
    "    if zipcode not in qmap:\n",
    "        return None\n",
    "\n",
    "    best_ratio = 0\n",
    "    best_match = None\n",
    "\n",
    "    for school in qmap[zipcode]:\n",
    "        ratio = SM(None, school_name, school[\"school_name\"]).ratio()\n",
    "        if ratio > best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_match = school\n",
    "    return {\"best_match\": best_match, \"ratio\": best_ratio}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function generates a hash for a given string\n",
    "# this is more realible in this workflow than using\n",
    "# the string itself since Excel is used in the\n",
    "# review/correction process and it butchers the\n",
    "# Chinese characters etc.\n",
    "\n",
    "import hashlib\n",
    "\n",
    "def generate_hash(input_string: str) -> str:\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(input_string.encode('utf-8'))    \n",
    "    return hash_object.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this secion reads the school list from the CA Dept of Education database\n",
    "# and creates a map of schools by zipcode which is used in the fn best_match\n",
    "# to find the best match for a given school name in a given zipcode\n",
    "# the map is then used to match the schools in the schoolList.json file\n",
    "# to the schools in the CA Dept of Education database by adding the school_code (casid)\n",
    "# to the school record.\n",
    "\n",
    "# It also creates a CSV file with the matches for review and correction. Excel can be used\n",
    "# to correct low quality/erroneous matches to produce an 'actions.csv' file that informs\n",
    "# the next step in the workflow on what changes need to be made to the schoolList.json file.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    dbname=db_name, user=db_user, password=db_password, host=\"localhost\", port=\"5432\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# SFUSD = '68478'\n",
    "cursor.execute(\n",
    "    \"SELECT school_code, school_name, zip_code from entities where county_code = '38';\"\n",
    ")\n",
    "\n",
    "results = cursor.fetchall()\n",
    "\n",
    "qmap = {}\n",
    "for scode, sname, szip in results:\n",
    "    if szip in qmap:\n",
    "        qmap[szip].append({\"school_code\": scode, \"school_name\": sname})\n",
    "    else:\n",
    "        qmap[szip] = [{\"school_code\": scode, \"school_name\": sname}]\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "#### read the json file\n",
    "with open(\"schoolList.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "csv_output = [\n",
    "    [\n",
    "        \"school_hash\",\n",
    "        \"school_uid\",\n",
    "        \"schoolLabel\",\n",
    "        \"schoolCode\",\n",
    "        \"zip\",\n",
    "        \"match_school_id\",\n",
    "        \"match_school_name\",\n",
    "        \"match_ratio\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "for school in data:\n",
    "    zip = f\"no zip for {school['schoolLabel']}\"\n",
    "    if \"geolocations\" in school:\n",
    "        location = school[\"geolocations\"][0][\"addressDetails\"]\n",
    "        schoolCode = school[\"schoolCode\"] if \"schoolCode\" in school else \"<missing>\"\n",
    "        if \"PostalCode\" in location:\n",
    "            zip = location[\"PostalCode\"].split(\"-\")[0]\n",
    "            \n",
    "            best = best_match(qmap, school[\"schoolLabel\"], zip)\n",
    "            match_school_id = best[\"best_match\"][\"school_code\"] if best else \"\"\n",
    "            match_school_name = best[\"best_match\"][\"school_name\"] if best else \"\"\n",
    "            match_ratio = best[\"ratio\"] if best else 0.0\n",
    "\n",
    "            school_unique_id = f\"{zip}-{school['schoolLabel']}\"\n",
    "            school_hash = generate_hash(f\"{school_unique_id}\")\n",
    "            \n",
    "            csv_output.append(\n",
    "                [\n",
    "                    str(school_hash),\n",
    "                    school_unique_id,\n",
    "                    school[\"schoolLabel\"],\n",
    "                    schoolCode,\n",
    "                    zip,\n",
    "                    match_school_id,\n",
    "                    match_school_name,\n",
    "                    f\"{float(match_ratio):.2f}\",\n",
    "                ]\n",
    "            )\n",
    "            school[\"school_hash\"] = school_hash\n",
    "            school[\"school_unique_id\"] = school_unique_id\n",
    "            school[\"casid\"] = match_school_id\n",
    "            # print(f\"added {school_unique_id} ({school_hash})\")\n",
    "        else:\n",
    "            print(f\"no zip for {school['schoolLabel']}\")\n",
    "    else:\n",
    "        print(f\"no geolocations for {school['schoolLabel']}\")\n",
    "\n",
    "# Write the CSV\n",
    "with open(\"matches.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for row in csv_output:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the bad school_codes\n",
    "\n",
    "Unfortunately, this is a manual part of the workflow. The school zipcodes are not always accurate which leads to bad matches. Moreover, the matching algorithm is not perfect. Where the match looks incorrect, the `casid` can be confirmed by looking at the SARC document for the school (located in Google Drive folders).\n",
    "\n",
    "The suggesed workflow is to open the `matches.csv` produced above in either Excel or another speadsheet package to review the matches. Be careful not to let Excel remove the zero-padding from the identifiers.\n",
    "\n",
    "After reviewing the matches, you need to create another CSV file with the correct casids. The file should have the following columns with no header row:\n",
    "\n",
    "- `school_hash`: The hash of the school name and zipcode (from the `matches.csv` file)\n",
    "- `casid`: The correct casid for the school\n",
    "- `instruction`: A note about the change either `KEEP`, `DELETE`, or `UPDATE`\n",
    "\n",
    "For example:\n",
    "\n",
    "```csv\n",
    "797c2568e4c71628d72d86379d7282ccc8a65a5aa4f13ea28958ae619f1736e8,6089569,OVERWRITE\n",
    "98f4714e5aade9a9465c99ccb07582aa0309787319074631df4b81f73a499242,6040752,DELETE\n",
    "e372d38bbc0d25217f22c4568fe6688df8f6ce9a296799d196b727469846a47b,6040752,KEEP\n",
    "19c4204704adb9868eb23780ee585451e596feb8346812a18382a2a108a991be,0102103,DELETE\n",
    "f948b5c086e43e7f885e93a8bd9d3cb8bb7f50388fd0751ab42e10ee76febfb0,3831765,KEEP\n",
    "e5ad922242f5110e8656a050a9affc0e595fcc42cbbbc6f7a5bc2bb7f6f30edb,6102479,KEEP\n",
    "```\n",
    "\n",
    "This file should be saved as `actions.csv` in the same directory as this notebook. It will be used in the next step to update the `schoolList.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section reads the actions.csv file and applies the changes to the schoolList.json file\n",
    "# by removing the schools that have been marked for deletion and updating the casid to the schools\n",
    "# the instructions in the actions.csv file. The updated schoolList.json file is then written to\n",
    "# schoolList_hashed.json\n",
    "\n",
    "with open(\"actions.csv\", mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    actions = [row for row in reader]\n",
    "\n",
    "del_list = [action[0] for action in actions if action[2] == \"DELETE\"]\n",
    "filtered = [school for school in data if school[\"school_hash\"] not in del_list]\n",
    "\n",
    "# create a dictionary of school_hash to casid\n",
    "casid_lookup = {action[0]: action[1] for action in actions if action[2] != \"DELETE\"}\n",
    "\n",
    "for school in filtered:\n",
    "    if not school[\"school_hash\"] in casid_lookup:\n",
    "        print(f\"no action for {school['schoolLabel']}\")\n",
    "    else:\n",
    "        school[\"casid\"] = casid_lookup.get(school[\"school_hash\"])\n",
    "\n",
    "# Write the JSON\n",
    "with open(\"schoolList_hashed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
